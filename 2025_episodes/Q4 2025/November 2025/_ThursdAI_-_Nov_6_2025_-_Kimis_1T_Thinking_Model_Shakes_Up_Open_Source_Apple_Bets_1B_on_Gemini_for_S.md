# üìÜ ThursdAI - Nov 6, 2025 - Kimi‚Äôs 1T Thinking Model Shakes Up Open Source, Apple Bets $1B on Gemini for Siri, and Amazon vs. Perplexity!

**Date:** November 07, 2025  
**Duration:** 1:32:45  
**Link:** [https://sub.thursdai.news/p/thursdai-nov-6-2025-kimis-1t-thinking](https://sub.thursdai.news/p/thursdai-nov-6-2025-kimis-1t-thinking)

---

## Description

Hey, Alex here! 

Quick note, while preparing for this week, I posted on X that I don‚Äôt remember such a quiet week in AI since I started doing ThursdAI regularly, but then 45 min before the show started, Kimi dropped a SOTA oss reasoning model, turning a quiet week into an absolute banger. 

Besides Kimi, we covered the updated MCP thinking from Anthropic, and had Kenton Varda from cloudflare as a guest to talk about Code Mode, chatted about Windsurf and Cursor latest updates and covered OpenAI‚Äôs insane deals. 

Also, because it was a quiet week, I figured I‚Äôd use the opportunity to create an AI powered automation, and used N8N for that, and shared it on the stream, so if you‚Äôre interested in automating with AI with relatively low code, this episode is for you. Let‚Äôs dive in

ThursdAI - Recaps of the most high signal AI weekly spaces is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.

**Kimi K2 Thinking is Here and It‚Äôs a 1 Trillion Parameter Beast! **([X](https://x.com/Kimi_Moonshot/status/1986449512538513505), [HF](https://huggingface.co/moonshotai/Kimi-K2-Thinking), [Tech Blog](https://moonshotai.github.io/Kimi-K2/thinking.html))

Let‚Äôs start with the news that got everyone‚Äôs energy levels skyrocketing right as we went live. Moonshot AI dropped Kimi K2 Thinking, an open-source, 1 trillion-parameter Mixture-of-Experts (MoE) model, and it‚Äôs an absolute monster.

This isn‚Äôt just a numbers game; Kimi K2 Thinking is designed from the ground up to be a powerful agent. With just around 32 billion active parameters during inference, a massive 256,000 token context window, and an insane tool-calling capacity. They‚Äôre claiming it can handle 200-300 sequential tool calls without any human intervention. 

The benchmarks are just as wild. On the Humanities Last Exam (HLE), they‚Äôre reporting a score of 44.9%, beating out both GPT-5 and Claude 4.5 Thinking. While it doesn‚Äôt quite top the charts on SWE-bench verified, it‚Äôs holding its own against the biggest closed-source models out there. Seeing an open-source model compete at this level is incredibly exciting.

During the show, we saw some truly mind-blowing demos, from a beautiful interactive visualization of gradient descent to a simulation of a virus attacking cells, all generated by the model. The model‚Äôs reasoning traces, which are exposed through the API, also seem qualitatively different from other models, showing a deep and thoughtful process. My co-hosts and I were blown away. The weights and a very detailed technical report are available on Hugging Face, so you can dive in and see for yourself. Shout out to the entire Moonshot AI team for this incredible release!

Other open source updates from this week

* HuggingFace released an open source ‚ÄúSmol Training Playbook‚Äù on training LLMs, it‚Äôs a 200+ interactive beast with visualizations, deep dives into pretraining, dataset, postraining and more! ([HF](https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook))

* Ai2 launches OlmoEarth ‚Äî foundation models + open, end-to-end platform for fast, high-resolution Earth intelligence ([X](https://x.com/allen_ai/status/1985719070407176577), [Blog](https://allenai.org/blog/olmoearth?utm_source=x&utm_medium=social&utm_campaign=olmoearth))

* LongCat-Flash-Omni ‚Äî open-source omni-modal system with millisecond E2E spoken interaction, 128K context and a 560B ScMoE backbone ([X](https://x.com/Meituan_LongCat/status/1984398560973242733), [HF](https://huggingface.co/meituan-longca), [Announcement](https://github.com/meituan-longca))

**Big Tech‚Äôs Big Moves: Apple, Amazon, and OpenAI**

The big companies were making waves this week, starting with a blockbuster deal that might finally make Siri smart. Apple is reportedly will be paying Google around $1 billion per year to license a custom 1.2 trillion-parameter version of Gemini to power a revamped Siri.

This is a massive move. The Gemini model will run on Apple‚Äôs Private Cloud Compute, keeping user data walled off from Google, and will handle Siri‚Äôs complex summarizer and planner functions. After years of waiting for Apple to make a significant move in GenAI, it seems they‚Äôre outsourcing the heavy lifting for now while they work to catch up with their own in-house models. As a user, I don‚Äôt really care who builds the model, as long as Siri stops being dumb!

In more dramatic news, Perplexity revealed that Amazon sent them a legal threat to block their Comet AI assistant from shopping on [Amazon.com](Amazon.com). This infuriated me. My browser is my browser, and I should be able to use whatever tools I want to interact with the web. Perplexity took a strong stand with their [blog post](https://perplexity.ai/hub/blog/bullying-is-not-innovation), ‚ÄúBullying is Not Innovation,‚Äù arguing that user agents are distinct from scrapers and act on behalf of the user with their own credentials. An AI assistant is just that‚Äîan assistant. It shouldn‚Äôt matter if I ask my wife or my AI to buy something for me on Amazon. This feels like a move by Amazon to protect its ad revenue at the expense of user choice and innovation, and I have to give major props to Perplexity for being so transparent and fighting back.

Finally, OpenAI continues its quest for infinite compute, announcing a multi-year strategic partnership with AWS. This comes on top of massive deals with NVIDIA, Microsoft, Oracle, and others, bringing their total commitment to compute into the trillions of dollars. It‚Äôs getting to a point where OpenAI seems ‚Äútoo big to fail,‚Äù as any hiccup could have serious repercussions for the entire tech economy, which is now heavily propped up by AI investment. Sam has clarified that they don‚Äôt think OpenAI wants to be too big to fail in a recent [post on X](https://x.com/sama/status/1986514377470845007), and that the recent miscommunications around the US government backstopping OpenAI‚Äôs infrastructure bailouts were taken out of context. ü§î 

**Coding with AI: The Evolution of MCP and New Dev Tools**

This week, we kicked off a new segment on the show: Coding with AI! Essentially realizing that we talk about AI coding a LOT, and decided to add a dedicated corner to it!  And we started with a fascinating development in the world of agentic tooling. Anthropic published a blog post arguing that the standard way of using the Model Context Protocol (MCP) ‚Äî by loading full tool definitions into the context window ‚Äî is inefficient.

Their solution? Have LLMs write code to interact with tools instead. This approach can slash token usage by over 98% in some cases. This idea sounded familiar, and that‚Äôs because Cloudflare had already [explored](https://blog.cloudflare.com/code-mode/) it with a feature called ‚ÄúCode Mode.‚Äù We were lucky enough to have [Kenton Varda](https://x.com/KentonVarda), one of the authors of the Code Mode post and head of engineering for Cloudflare Workers, join us to discuss this shift.

Kenton explained that LLMs are trained on vast amounts of code, making it a more ‚Äúnative language‚Äù for them than the artificial construct of tool calls. By generating code, agents can chain multiple tool calls together, process intermediate results, and operate much more efficiently without sending everything back through the neural network. While MCP still provides crucial standardization for discovering and authorizing tools, this ‚Äúcode execution‚Äù pattern seems to be the way forward for building more powerful and scalable agents.

Windsurfs CodeMaps and Cursor multi agent executions

In other coding with AI news, Windsurf has pushed an incredible feature, called CodeMaps. They will use their SWE-1 model to (quickly) generate Codemaps that will expalins a code-base to you, in a visual way. What starts where and goes where. It‚Äôs really useful to understand a new codebase or re-understand one you forgot about already! You can even chat with codemaps, to see if your overall system‚Äôs design is solid! Great addition that I‚Äôm sure will help many folks adopt Windsurf! 

And Cursor, another popular AI-native IDE, released a super-performant in-IDE browser and a wild multi-agent feature that queries multiple LLMs in parallel and then synthesizes their answers.

**This Week‚Äôs Tutorial**

I finally got around to building some serious automations for ThursdAI, and folks, N8N has been a game-changer. What used to take me 30+ minutes of manual work now happens automatically in the background.

Here‚Äôs what I built: A Telegram bot that takes Twitter/X links, fetches the tweets and all linked content, uses AI agents to extract and summarize the information, and then posts it to our announcement channel and my notes app. The coolest part? I built this whole thing in about 4 hours with the help of Atlas browser and GPT-5 literally telling me what to do at each step.

During the show, we even live-tested swapping out GPT-4o-mini for Kimi K2 - took literally 30 seconds to connect via OpenRouter. I went through my node and explains how this all works on the show, so if you‚Äôve wanted to learn about n8n, check it out starting around 01:13:00. If you want to see how my automation turned out, it will be posting all my links to the new telegram channel [t.me/thursdai_news](http://t.me/thursdai_news) (expect it to be messy at first as I‚Äôm testing out the automation) 

**Robotics - Xpeng‚Äôs ‚ÄúIron‚Äù humanoid: big vibes, few specs**

Another week, another humanoid robot that is supposedly ‚Äúcoming‚Äù in 2026! 

A humanoid from Xpeng went viral this week, marketed as ‚Äúthe most human‚Äëlike‚Äù robot with soft skin, bionic muscles, customizable sexes (yes, really, they have a woman humanoid), something called a VLT brain, and a 2026 production goal. Here‚Äôs what we didn‚Äôt get: a spec sheet. No DOF, speed, payload, compute TOPS, battery capacity, runtime, or safety pathway. No pricing, manufacturing strategy, or clear target markets. In other words: lots of sizzle, no steak.

Apparently, there was folks thinking Xpend pulled an Elon and put a human in a robot suit, making the CEO do the ‚Äúwe‚Äôll cut a part of the soft skin to expose the robot underneath so you don‚Äôt think we‚Äôre lying‚Äù stunt. Which I agree, was very effective. 

But, If Xpeng is serious, the next thing we‚Äôll see should be a crisp engineering document: joints, actuation, sensors, compute, and a locomotion/manipulation demo with independent measurements. Until then, treat this as a branding salvo and a reminder that the humanoid category is still sorting itself into ‚Äúindustrial payload first‚Äù versus ‚Äúhuman likeness first‚Äù approaches. 

**Voice & Audio**

**Maya‚Äë1: open‚Äësource voice design from natural language**

We highlighted Maya‚Äë1, a 3B Llama‚Äëbackboned TTS system designed to generate voices from natural language descriptions. Instead of picking from a menu, you describe the voice‚Äîage, accent, affect‚Äîand Maya conjures it. It supports real‚Äëtime streaming and over twenty ‚Äúemotion tags.‚Äù The quality is compelling for its size and the Apache 2 license will make a lot of builders happy. There‚Äôs a growing middle class of TTS: tiny but expressive, good enough for in‚Äëapp narrators, prototyping, and even stylized content when you don‚Äôt want the constraints of commercial voice marketplaces.

**Inworld TTS: a new leader on independent rankings**

We also listened to Inworld‚Äôs latest, which currently tops the Artificial Analysis TTS leaderboard. It‚Äôs not open source, but the combo of expressivity, speed (sub‚Äë250 ms), and multilingual support puts it firmly in the ‚Äúcommercially viable at scale‚Äù tier alongside the usual suspects. If you need SaaS TTS today and care about emotional range, add this to your shortlist. Pricing on their site targets availability rather than hobbyist tinkering, but the quality argues for itself.

Whew! For a week that started slow, it certainly ended with a bang. It just goes to show you can never count AI out. We‚Äôre seeing open source continue to push the boundaries, big tech making landscape-defining moves, and agentic AI becoming more powerful and accessible every day.

As always, thanks for tuning in. If you‚Äôre going to be at the [AI.engineer](AI.engineer) conference in New York, please hit me up‚ÄîI‚Äôd love to meet you.

TL;DR and Show Notes + Links

* **Hosts and Guests**

* **Alex Volkov** - AI Evangelist & Weights & Biases ([@altryne](http://x.com/@altryne))

* Co Hosts - [@WolframRvnwlf](http://x.com/@WolframRvnwlf) @yampeleg [@nisten](http://x.com/@nisten)

* Kenton Varda @ Cloudflare ([@KentonVarda](https://x.com/KentonVarda))

* **Open Source LLMs**

* Smol Training Playbook ‚Äî a 200+ page, end-to-end guide to reliably pretrain and operate LLMs ([X](https://x.com/eliebakouch/1983930328751153159), [Announcement](https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook))

* Ai2 launches OlmoEarth ‚Äî foundation models + open, end-to-end platform for fast, high-resolution Earth intelligence ([X](https://x.com/allen_ai/1985719070407176577), [Blog](https://allenai.org/blog/olmoearth?utm_source=x&utm_medium=social&utm_campaign=olmoearth))

* Moonshot AI releases Kimi K2 Thinking ‚Äî an open-source 1T-parameter MoE agent with 256K context and huge tool-calling capacity ([X](https://x.com/Kimi_Moonshot/1986449512538513505), [HF](https://huggingface.co/moonshotai/Kimi-K2-Thinking), [Blog](https://moonshotai.github.io/Kimi-K2/thinki), [Arxiv](https://huggingface.co/papers/2510.26692))

* LongCat flash Omni - 560B (27A) omni model (text, audio, video input)

* **Big CO LLMs + APIs**

* Apple will pay roughly $1B/year to license a custom 1.2 trillion‚Äëparameter Google Gemini model to power a revamped Siri ([X](https://x.com/markgurman/1986150242698637591), [Announcement](https://www.bloomberg.com/news/articles/2025-11-05/apple-plans-to-use-1-2-trillion-parameter-google-gemini-model-to-power-new-siri?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc2MjM3MDAzOSwiZXhwIjoxNzYyOTc0ODM5LCJhcnRpY2xlSWQiOiJUNTZETzhHUTdMMFIwMCIsImJjb25uZWN0SWQiOiJDNEVEQ0FFMUZBMDU0MEJFQTI0QTlGMjExQzFFOTA4MCJ9._aWk2P25J89KBRkJQ_KdbwuULLM8yUtrPCPfRmsUfSs))

* Perplexity says Amazon issued a legal threat to block Comet AI assistants from shopping on Amazon ([X](https://x.com/perplexity_ai/1985774904911020319), [Blog](https://perplexity.ai/hub/blog/bullying-is-not-innovation))

* AWS announces multi-year strategic infrastructure partnership with OpenAI to power ChatGPT inference, training, and agentic AI ([X](https://x.com/ajassy/1985351258333643172))

* **Robotics**

* Xpeng unveils ‚ÄòIron‚Äô humanoid claiming ‚Äòmost human-like‚Äô design with soft skin, bionic muscles, VLT brain and a 2026 production plan ([X](https://x.com/humanoidsdaily/1986063827327201757))

* **Coding with AI**

* Anthropic shows how running MCP-connected tools as code slashes token use and scales agents ([X](https://x.com/AnthropicAI/1985846791842250860), [Blog](https://www.anthropic.com/engineering/code-execution-with-mcp))

* Windsurf Codemaps ‚Äî AI‚Äëannotated, navigable maps of your codebase powered by SWE-1.5 (Fast) and Sonnet 4.5 (Smart) ([X](https://x.com/cognition/1985755284527010167), [Announcement](https://cognition.ai/blog/codemaps))

* Conversation with Kenton Varda ([@KentonVarda](https://x.com/KentonVarda)) from Cloudflare about MCP and Code Mode

* Cursor added in IDE browser - very performant!

* **Audio & Video**

* Maya-1 - Open source voice generation model.

* Inworld TTS - new #1 on artifical analysis benchmark.

* **Tools & Gadgets**

* Sandbar launches Stream ‚Äî a voice-first personal assistant ‚Äî and Stream Ring, a wearable ‚Äòmouse for voice‚Äô, available for preorder ([X](https://x.com/sandbar/status/1986112726889078911), [Blog](https://www.sandbar.com/stream)) 

Thank you for subscribing. [Leave a comment](https://sub.thursdai.news/p/thursdai-nov-6-2025-kimis-1t-thinking/comments?utm_medium=podcast&utm_campaign=CTA_5) or [share this episode](https://sub.thursdai.news/p/thursdai-nov-6-2025-kimis-1t-thinking?utm_source=substack&utm_medium=podcast&utm_content=share&action=share&token=eyJ1c2VyX2lkIjoxNTIyMTYxMTAsInBvc3RfaWQiOjE3ODIzMTU1OSwiaWF0IjoxNzY1MjQyMjg2LCJleHAiOjE3Njc4MzQyODYsImlzcyI6InB1Yi0xODAxMjI4Iiwic3ViIjoicG9zdC1yZWFjdGlvbiJ9.k6cFVokVpTFW7F_weCQScyDI2A-VEWVsF24x9oRpUjs&utm_campaign=CTA_5).
